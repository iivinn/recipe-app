Building a YOLOv8 Model for General Food Recognition

Goal:

The goal is to create a YOLOv8-based model that can recognize a wide variety of food-related items in images. This includes fruits, vegetables, sauces, liquids, groceries, and packaged foods, not just cooked dishes. The model should be capable of detecting and classifying individual ingredients or grocery items such as apple, lemon, broccoli, ketchup, milk, olive oil, rice, steak, and tomato sauce.

Core Datasets for Food and Ingredient Detection

a. Open Images Dataset (Food Subset)

Description:
One of the most comprehensive datasets for general object detection. It contains millions of annotated images with bounding boxes and class labels. The food subset includes numerous items like apple, banana, bread, orange, bottle, tomato, sandwich, pasta, and more.

Why It’s Useful:
Excellent for training a model to detect individual food items rather than entire dishes. It provides bounding boxes, which YOLOv8 requires.

How to Use:
You can extract food-related classes using the class hierarchy CSV file provided by Google, or use a pre-filtered subset from a platform like Roboflow.

Scale:
Hundreds of thousands of labeled food instances.

Recommendation:
Use this as the backbone of the dataset. Train YOLOv8 first on this dataset before fine-tuning with smaller, specialized datasets.

b. UECFOOD-256

Description:
A dataset containing 256 categories of food with bounding box annotations. It includes many international dishes such as sushi, curry, noodles, and dumplings.

Why It’s Useful:
Adds cultural diversity and helps the model recognize plated meals.

Limitation:
Focuses on dishes rather than raw ingredients, but still valuable for variety and realism.

c. Fruits-360

Description:
Contains over 90,000 images of 131 classes of fruits and vegetables. Images are typically centered with plain backgrounds.

Why It’s Useful:
Excellent for training the model to distinguish between similar fruits or vegetables, such as orange vs. tangerine or apple vs. pear.

Limitation:
Does not include bounding boxes. However, simple scripts can automatically generate bounding boxes around centered fruits so the dataset can be converted to YOLO format.

Source:
Available on Kaggle under the name “Fruits-360”.

d. Grocery Store Image Dataset

Description:
A collection of grocery product images including cereals, bottles, jars, and packaged goods.

Why It’s Useful:
Adds real-world supermarket context to the dataset. Helps the model learn to identify packaged and labeled products, not just raw foods.

Source:
Available on Kaggle under the name “Grocery Store Dataset”.

e. FoodSeg103 and FoodSeg155

Description:
Datasets that contain pixel-level segmentation masks of complex plated foods.

Why It’s Useful:
These datasets represent realistic multi-ingredient dishes such as rice, vegetables, and sauces. The segmentation masks can easily be converted to bounding boxes for YOLOv8 training.

Conversion Note:
You can use a script to convert segmentation masks to bounding boxes before training.

Combining Datasets for YOLOv8 Training

To train YOLOv8 effectively, datasets from different sources need to be standardized and merged.

Step 1: Normalize Class Labels
Ensure all datasets use consistent naming conventions. For example, use “apple” instead of “apples” and “olive_oil” instead of “oil bottle”.

Step 2: Convert to YOLO Format
Each image must have a corresponding text file with bounding box annotations in the format required by YOLOv8. All coordinate values are normalized between 0 and 1.

Step 3: Create a YAML Configuration File
YOLOv8 uses a YAML file to locate training and validation data and define the list of classes. The file should specify the dataset paths, the number of classes, and their names.

Step 4: Train the Model
Once the data and configuration are ready, you can begin training YOLOv8 using your merged dataset. The training command includes parameters for data path, model architecture, number of epochs, and image size.

Recommended Dataset Mix

Purpose: Ingredient-level food items
Dataset: Open Images (Food subset)
Role: Core backbone

Purpose: Regional and plated dishes
Dataset: UECFOOD-256
Role: Supplementary

Purpose: Raw fruits and vegetables
Dataset: Fruits-360
Role: Fine-tuning and precision

Purpose: Packaged groceries
Dataset: Grocery Store Dataset
Role: Real-world expansion

Purpose: Multi-ingredient meals
Dataset: FoodSeg103 and FoodSeg155
Role: Scene diversity

Data Augmentation and Realism Enhancements

To increase robustness and real-world accuracy, apply data augmentation and synthesis techniques.

Background Replacement:
Replace plain backgrounds with realistic kitchen, grocery, or dining settings.

Lighting and Color Variation:
Apply brightness, hue, contrast, and blur augmentations during training using YOLOv8’s built-in augmentation tools.

Synthetic Image Generation:
Combine isolated ingredient images (such as those from Fruits-360) with random backgrounds to simulate natural scenes.

Dataset Cleaning and Merging Tools:
Use tools like Roboflow or FiftyOne to merge, relabel, and visualize your datasets consistently.

Summary

To build a YOLOv8 model capable of detecting and classifying a wide range of food types, the best approach is to start with the Open Images food subset as the foundation. Then fine-tune with targeted datasets like UECFOOD-256, Fruits-360, the Grocery Store Dataset, and FoodSeg103 or FoodSeg155 for completeness and diversity.

Combining these datasets will yield a robust detector for fruits, vegetables, sauces, liquids, packaged groceries, and complete meals. This will enable both general ingredient recognition and contextual understanding of complex food scenes.
